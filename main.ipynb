{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = \"2024-01-30\"\n",
    "month = \"12 dec 2023\"  # note: used to retrieve sheet from coco trainer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "def load_pending_df(path_: str) -> pd.DataFrame:\n",
    "    \"\"\"Load pending result DF.\"\"\"\n",
    "\n",
    "    df = pd.read_excel(path_, skiprows=1, engine=\"xlrd\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_all_pending_dfs(path_: str) -> list[pd.DataFrame]:\n",
    "    \"\"\"Load all pending result DFs, return them as a list of DFs.\"\"\"\n",
    "\n",
    "    offline_classroom = load_pending_df(Path(path_, \"Pending Results.xls\"))\n",
    "    offline_other = load_pending_df(Path(path_, \"Pending Results (1).xls\"))\n",
    "    online_classroom = load_pending_df(Path(path_, \"Pending Results (2).xls\"))\n",
    "    online_other = load_pending_df(Path(path_, \"Pending Results (3).xls\"))\n",
    "    return [offline_classroom, offline_other, online_classroom, online_other]\n",
    "\n",
    "\n",
    "def load_trainer_df(month: str) -> pd.DataFrame:\n",
    "    \"\"\"Load trainer DF which details the area of ET.\"\"\"\n",
    "\n",
    "    path = \"/home/anj/Documents/wse-local/2. Experience/dependencies/coco_trainer_data.xlsx\"\n",
    "    df_trainer = pd.read_excel(path, sheet_name=month)\n",
    "\n",
    "    return df_trainer\n",
    "\n",
    "\n",
    "def clean_trainer_name(df: pd.DataFrame, teacher_col: str) -> pd.Series:\n",
    "    \"\"\"Clean teacher's name.\"\"\"\n",
    "\n",
    "    teachers = (\n",
    "        df[teacher_col]\n",
    "        .str.title()\n",
    "        .str.replace(\"\\(.+\\)\", \"\", regex=True)\n",
    "        .str.replace(\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "        .replace(\n",
    "            {\n",
    "                \"Azhar Rahul\": \"Azhar Rahul Finaya\",\n",
    "                \"Handayani Risma\": \"Handayani Khaerunisyah Risma\",\n",
    "                \"Kartikasari Prettya\": \"Kartikasari Prettya Nur\",\n",
    "                \"Ramadhan Ira Ragil\": \"Ramadhani Ira\",\n",
    "                \"S Allan\": \"Santiago Allan\",\n",
    "                \"Gandhama Jesita\": \"Ghandama Jesita\",\n",
    "                \"Istiqomah Diah\": \"Toluhula Diah Istiqomah\",\n",
    "                \"Putri Tiara\": \"Setiawan Tiara Putri\",\n",
    "                \"Hamsah Ratnasari Handayani\": \"Hamsah Handayani Ratnasari\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return teachers\n",
    "\n",
    "\n",
    "def clean_pending_df(dfs: list, date_exported: str, month: str) -> pd.DataFrame:\n",
    "    \"\"\"Clean pending dfs to obtain list of pending results per session.\"\"\"\n",
    "\n",
    "    df_clean = (\n",
    "        # concat dfs that is obtained from load_all_pending_dfs\n",
    "        pd.concat(dfs)\n",
    "        # drop unused columns\n",
    "        .drop(\n",
    "            columns=[\"Level / Unit\", \"First Name\", \"Last Name\", \"Code\", \"Service Type\"]\n",
    "        )\n",
    "        # drop duplicates based on this subset to get per session\n",
    "        .drop_duplicates(\n",
    "            subset=[\"Teacher\", \"Class Type\", \"Date\", \"Start Time\"], keep=\"first\"\n",
    "        )\n",
    "        # rename columns\n",
    "        .rename(columns=lambda c: c.lower().replace(\"_\", \" \"))\n",
    "        # drop na rows and cols\n",
    "        .dropna(subset=[\"teacher\"])\n",
    "        .dropna(how=\"all\", axis=0)\n",
    "        .dropna(how=\"all\", axis=1)\n",
    "        .assign(\n",
    "            teacher=lambda df_: clean_trainer_name(\n",
    "                df_, \"teacher\"\n",
    "            ),  # clean teacher name\n",
    "            date=lambda df_: pd.to_datetime(df_[\"date\"]),  # get the clean date\n",
    "            date_exported=pd.to_datetime(date_exported),  # data exported date\n",
    "        )\n",
    "        # merge with et data to get area and position\n",
    "        .merge(\n",
    "            right=load_trainer_df(month),\n",
    "            left_on=\"teacher\",\n",
    "            right_on=\"teacher\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        # drop unused cols\n",
    "        .drop(\n",
    "            columns=[\n",
    "                \"teacher_working_days\",\n",
    "                \"teacher_note_1\",\n",
    "                \"teacher_note_2\",\n",
    "                \"center name\",\n",
    "            ]\n",
    "        )\n",
    "        # sort columns\n",
    "        .loc[\n",
    "            :,\n",
    "            [\n",
    "                \"teacher\",\n",
    "                \"date\",\n",
    "                \"start time\",\n",
    "                \"class type\",\n",
    "                \"teacher_position\",\n",
    "                \"teacher_center\",\n",
    "                \"teacher_area\",\n",
    "                \"date_exported\",\n",
    "            ],\n",
    "        ]\n",
    "        # sort rows\n",
    "        .sort_values([\"teacher_area\", \"teacher_center\", \"teacher\", \"date\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def count_pending_result(df: pd.DataFrame, today: str) -> pd.DataFrame:\n",
    "    \"\"\"Get summary of pending result in the last 365 days,\n",
    "    grouped by area and teacher, pivoted per month.\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        # filter only pending result for the past 365 days\n",
    "        .loc[lambda df_: (pd.to_datetime(today) - df_[\"date\"]).dt.days <= 365]\n",
    "        # group\n",
    "        .groupby([\"teacher_area\", \"teacher\", pd.Grouper(key=\"date\", freq=\"1M\")])\n",
    "        .agg(num_session_with_pending_res=(\"teacher\", \"count\"))\n",
    "        .reset_index()\n",
    "        # pivot\n",
    "        .pivot(index=[\"teacher_area\", \"teacher\"], columns=\"date\")\n",
    "        # fill na with 0\n",
    "        .fillna(0)\n",
    "        # note: do not display trainer if the last 3 months pending results is 0\n",
    "        .loc[lambda df_: np.sum(df_.iloc[:, -3:], axis=1) > 0]\n",
    "        # clean col names and all\n",
    "        .droplevel(0, axis=1)\n",
    "        .rename(columns=lambda c: c.strftime(\"%b %Y\"))\n",
    "        .rename_axis([\"Teacher Area\", \"Teacher\"])\n",
    "        .rename_axis([\"\"], axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** file size (287331) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (1303139) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (6819) not 512 + multiple of sector size (512)\n",
      "WARNING *** file size (402019) not 512 + multiple of sector size (512)\n"
     ]
    }
   ],
   "source": [
    "# load all pending dfs in a folder\n",
    "dfs = load_all_pending_dfs(Path(\"data\", today))\n",
    "# clean data\n",
    "df_clean = clean_pending_df(dfs, today, month)\n",
    "# count pending result per month / create summary\n",
    "df_pending = count_pending_result(df_clean, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_teacher_exist_in_coco_trainer_data():\n",
    "    unmapped = df_clean.loc[df_clean[\"teacher_area\"].isna(), \"teacher\"].unique()\n",
    "    assert (\n",
    "        unmapped.shape[0] == 0\n",
    "    ), f\"some teacher are not listed in coco_trainer_data: {unmapped}\"\n",
    "\n",
    "\n",
    "test_all_teacher_exist_in_coco_trainer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data per area\n",
    "df_clean = df_clean.rename(columns=lambda c: c.replace(\"_\", \" \").title())\n",
    "df_jkt1 = df_clean.loc[df_clean[\"Teacher Area\"] == \"JKT 1\"]\n",
    "df_jkt2 = df_clean.loc[df_clean[\"Teacher Area\"] == \"JKT 2\"]\n",
    "df_jkt3 = df_clean.loc[df_clean[\"Teacher Area\"] == \"JKT 3\"]\n",
    "df_sby = df_clean.loc[df_clean[\"Teacher Area\"] == \"SBY\"]\n",
    "df_bdg = df_clean.loc[df_clean[\"Teacher Area\"] == \"BDG\"]\n",
    "df_onl = df_clean.loc[\n",
    "    df_clean[\"Teacher Area\"].isin([\"Online\", \"Shared Account\", \"Ooolab\"])\n",
    "]\n",
    "df_oth = df_clean.loc[df_clean[\"Teacher Area\"] == \"Other\"]\n",
    "\n",
    "# assert that no rows are missed\n",
    "assert len(df_clean) == sum(\n",
    "    [len(df) for df in [df_jkt1, df_jkt2, df_jkt3, df_sby, df_bdg, df_onl, df_oth]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df\n",
    "# write each dataframe to a different worksheet.\n",
    "\n",
    "filename = \"output.xlsx\"\n",
    "filepath = os.path.join(\"data\", today, filename)\n",
    "writer = pd.ExcelWriter(filepath, engine=\"xlsxwriter\")\n",
    "\n",
    "df_pending.to_excel(writer, sheet_name=\"Summary\", index=True)\n",
    "df_clean.to_excel(writer, sheet_name=\"All Area\", index=False)\n",
    "df_jkt1.to_excel(writer, sheet_name=\"JKT 1\", index=False)\n",
    "df_jkt2.to_excel(writer, sheet_name=\"JKT 2\", index=False)\n",
    "df_jkt3.to_excel(writer, sheet_name=\"JKT 3\", index=False)\n",
    "df_sby.to_excel(writer, sheet_name=\"SBY\", index=False)\n",
    "df_bdg.to_excel(writer, sheet_name=\"BDG\", index=False)\n",
    "df_onl.to_excel(writer, sheet_name=\"Online\", index=False)\n",
    "df_oth.to_excel(writer, sheet_name=\"Other\", index=False)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
